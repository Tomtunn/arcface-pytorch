{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter, DataParallel\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data.sampler import BatchSampler, RandomSampler\n",
    "from torchvision import transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import shutil\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_df(identity_root, identity_list):\n",
    "    path_list = []\n",
    "    identity_label_list = []\n",
    "    for identity in tqdm(identity_list):\n",
    "        image_list = os.listdir(os.path.join(identity_root, identity)) \n",
    "        for img in image_list:\n",
    "            path = os.path.join(identity_root, identity, img)\n",
    "            path_list.append(path)\n",
    "            identity_label_list.append(identity) \n",
    "\n",
    "    data_df = pd.DataFrame({'img_path': path_list, 'identity': identity_label_list})\n",
    "    data_df['identity_code'] = pd.Categorical(data_df['identity']).codes # convert identity to unique code(int)\n",
    "    data_df['identity_code'] = data_df['identity_code'].astype('int32')\n",
    "    return data_df\n",
    "\n",
    "# save numpy array from path\n",
    "def get_img_npy(path_df, img_shape):\n",
    "    img_npy = np.zeros((len(path_df), img_shape[0], img_shape[1], img_shape[2]), dtype=np.uint8)\n",
    "    label_npy = np.zeros((len(path_df), 1), dtype=np.uint8)\n",
    "    for i in tqdm(range(len(path_df)), desc='get_img_npy'):\n",
    "        img_path = path_df.iloc[i]['img_path']\n",
    "        img = Image.open(img_path)\n",
    "        img_npy[i] = np.array(img)\n",
    "        label_npy[i] = path_df.iloc[i]['identity_code']\n",
    "    return img_npy, label_npy \n",
    "\n",
    "def save_chunk_npy(path_df, num_chunk, img_shape, root):\n",
    "    path_df_list = np.array_split(path_df, num_chunk)\n",
    "    for i in range(len(path_df_list)):\n",
    "        img_npy, label_npy = get_img_npy(path_df_list[i], img_shape)\n",
    "        np.save(os.path.join(root, 'data_{}.npy'.format(i)), img_npy)\n",
    "        np.save(os.path.join(root, 'label_{}.npy'.format(i)), label_npy)\n",
    "\n",
    "def get_pair_npy(pair_df, img_shape):\n",
    "    img_npy1 = np.zeros((len(pair_df), img_shape[0], img_shape[1], img_shape[2]), dtype=np.uint8)\n",
    "    img_npy2 = np.zeros((len(pair_df), img_shape[0], img_shape[1], img_shape[2]), dtype=np.uint8)\n",
    "    label_npy = np.zeros((len(pair_df), 1), dtype=np.uint8)\n",
    "    for i in tqdm(range(len(pair_df)), desc='get_pair_npy'):\n",
    "        img_path1 = pair_df.iloc[i]['img1_path']\n",
    "        img_path2 = pair_df.iloc[i]['img2_path']\n",
    "        img1 = Image.open(img_path1)\n",
    "        img2 = Image.open(img_path2)\n",
    "        img_npy1[i] = np.array(img1)\n",
    "        img_npy2[i] = np.array(img2)\n",
    "        label_npy[i] = pair_df.iloc[i]['label']\n",
    "    return img_npy1, img_npy2, label_npy\n",
    "\n",
    "def save_chunk_pair_npy(pair_df, num_chunk, img_shape, root):\n",
    "    pair_df_list = np.array_split(pair_df, num_chunk)\n",
    "    for i in range(num_chunk):\n",
    "        img_npy1, img_npy2, label_npy = get_pair_npy(pair_df_list[i], img_shape)\n",
    "        np.save(os.path.join(root, 'img1_{}.npy'.format(i)), img_npy1)\n",
    "        np.save(os.path.join(root, 'img2_{}.npy'.format(i)), img_npy2)\n",
    "        np.save(os.path.join(root, 'label_{}.npy'.format(i)), label_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, img_npy_list, label_npy_list, input_shape, phase=\"train\"):\n",
    "        self.img_npy = np.vstack(img_npy_list)\n",
    "        self.label_npy = np.vstack(label_npy_list)\n",
    "        self.phase = phase\n",
    "        self.input_shape = input_shape\n",
    "        if self.phase == 'train':\n",
    "            self.transforms = T.Compose([\n",
    "                T.RandomCrop(self.input_shape[1:]),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.5], std=[0.5])\n",
    "            ])\n",
    "        else:   \n",
    "            self.transforms = T.Compose([\n",
    "                T.CenterCrop(self.input_shape[1:]),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.5], std=[0.5])\n",
    "            ])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.label_npy.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.img_npy[index]\n",
    "        label = self.label_npy[index]\n",
    "        data = Image.fromarray(data)\n",
    "        data = data.convert('RGB')\n",
    "        data = self.transforms(data)\n",
    "        return data.float(), label.squeeze()\n",
    "    \n",
    "class PairFaceDataset(Dataset):\n",
    "    def __init__(self, img_npy_list1, img_npy_list2, label_npy_list, input_shape):\n",
    "        self.img_npy1 = np.vstack(img_npy_list1)\n",
    "        self.img_npy2 = np.vstack(img_npy_list2)\n",
    "        self.label_npy = np.vstack(label_npy_list)\n",
    "        self.input_shape = input_shape\n",
    "        self.transforms = T.Compose([\n",
    "            T.CenterCrop(self.input_shape[1:]),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.label_npy.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data1 = self.img_npy1[index]\n",
    "        data1 = Image.fromarray(data1)\n",
    "        data1 = data1.convert('RGB')\n",
    "        data1 = self.transforms(data1)\n",
    "\n",
    "        data2 = self.img_npy2[index]\n",
    "        data2 = Image.fromarray(data2)\n",
    "        data2 = data2.convert('RGB')\n",
    "        data2 = self.transforms(data2)\n",
    "        label = self.label_npy[index]\n",
    "        return data1.float(), data2.float(), label.squeeze()\n",
    "    \n",
    "class BalancedBatchSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, dataset, n_classes, n_samples):\n",
    "        self.dataset = dict()\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.idx_to_class = []\n",
    "        self.class_to_idx = {}\n",
    "        for idx, (data, label) in enumerate(dataset):\n",
    "            if label not in self.class_to_idx:\n",
    "                self.class_to_idx[label] = []\n",
    "                self.idx_to_class.append(label)\n",
    "            self.class_to_idx[label].append(idx)\n",
    "        for c in self.class_to_idx:\n",
    "            self.dataset[c] = torch.utils.data.Subset(dataset, self.class_to_idx[c])\n",
    "        self.length = min([len(self.class_to_idx[c]) for c in self.class_to_idx]) * len(self.class_to_idx)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for c in self.class_to_idx:\n",
    "            random.shuffle(self.class_to_idx[c])\n",
    "        for i in range(self.length // self.n_samples):\n",
    "            classes = random.sample(self.class_to_idx.keys(), self.n_classes)\n",
    "            for c in classes:\n",
    "                for idx in self.class_to_idx[c][:self.n_samples]:\n",
    "                    yield idx\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee0f4b998e343989d44d3d71ae1a77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5749 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 10585, val: 1324, test: 1323\n",
      "5749\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "npy_root = 'lfw_funneled_npy'\n",
    "identity_root = 'lfw_funneled'\n",
    "identity_list = os.listdir(identity_root)\n",
    "identity_list = [identity for identity in identity_list if os.path.isdir(os.path.join(identity_root, identity))] #only folder is identity\n",
    "\n",
    "# total data for test\n",
    "path_df = get_path_df(identity_root, identity_list)\n",
    "\n",
    "# train test val split\n",
    "train_df, test_df = train_test_split(path_df, test_size=0.2, random_state=42)\n",
    "test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "print('train: {}, val: {}, test: {}'.format(len(train_df), len(val_df), len(test_df)))\n",
    "\n",
    "img_npy_list = [np.load(os.path.join(npy_root, 'data_1.npy'))]\n",
    "label_npy_list = [np.load(os.path.join(npy_root, 'label_1.npy'))]\n",
    "\n",
    "input_shape = (1, 250, 250)\n",
    "phase = 'train'\n",
    "dataset = FaceDataset(img_npy_list, label_npy_list, input_shape, phase)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "num_classes = len(np.unique(path_df['identity'].values))\n",
    "print(num_classes)\n",
    "\n",
    "# pair dataloader\n",
    "root = 'data/test_pair'\n",
    "img_npy_list1 = [np.load(os.path.join(root, 'img1_0.npy'))]\n",
    "img_npy_list2 = [np.load(os.path.join(root, 'img2_0.npy'))]\n",
    "label_npy_list = [np.load(os.path.join(root, 'label_0.npy'))]\n",
    "\n",
    "input_shape = (3, 250, 250)\n",
    "pair_dataset = PairFaceDataset(img_npy_list1, img_npy_list2, label_npy_list, input_shape)\n",
    "pair_dataloader = DataLoader(pair_dataset, batch_size=16, shuffle=True)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 250, 250])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for data, label in dataloader:\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "model_resnet = resnet18(weights=None)\n",
    "# change first and last layer\n",
    "model_resnet.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model_resnet.fc = nn.Linear(512, 512)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    r\"\"\"Implement of large margin arc distance:\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample\n",
    "            s: norm of input feature\n",
    "            m: margin\n",
    "\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m #cos(target+margin)\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
    "        output *= self.s\n",
    "        return output\n",
    "    \n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist = F.pairwise_distance(anchor, positive, 2)\n",
    "        neg_dist = F.pairwise_distance(anchor, negative, 2)\n",
    "        basic_loss = pos_dist - neg_dist + self.margin\n",
    "        loss = torch.mean(torch.max(basic_loss, torch.zeros_like(basic_loss)))\n",
    "        return loss \n",
    "    \n",
    "def l2_norm(input, axis = 1):\n",
    "    norm = torch.norm(input, 2, axis, True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "    \n",
    "class CurricularFace(nn.Module):\n",
    "    def __init__(self, in_features, out_features, m = 0.5, s = 64.):\n",
    "        super(CurricularFace, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.m = m\n",
    "        self.s = s\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.threshold = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "        self.kernel = Parameter(torch.Tensor(in_features, out_features))\n",
    "        self.register_buffer('t', torch.zeros(1))\n",
    "        nn.init.normal_(self.kernel, std=0.01)\n",
    "\n",
    "    def forward(self, embbedings, label):\n",
    "        embbedings = l2_norm(embbedings, axis = 1)\n",
    "        kernel_norm = l2_norm(self.kernel, axis = 0)\n",
    "        cos_theta = torch.mm(embbedings, kernel_norm)\n",
    "        cos_theta = cos_theta.clamp(-1, 1)  # for numerical stability\n",
    "        with torch.no_grad():\n",
    "            origin_cos = cos_theta.clone()\n",
    "        target_logit = cos_theta[torch.arange(0, embbedings.size(0)), label.long()].view(-1, 1)\n",
    "\n",
    "        sin_theta = torch.sqrt(1.0 - torch.pow(target_logit, 2))\n",
    "        cos_theta_m = target_logit * self.cos_m - sin_theta * self.sin_m #cos(target+margin)\n",
    "        mask = cos_theta > cos_theta_m\n",
    "        final_target_logit = torch.where(target_logit > self.threshold, cos_theta_m, target_logit - self.mm)\n",
    "\n",
    "        hard_example = cos_theta[mask]\n",
    "        with torch.no_grad():\n",
    "            self.t = target_logit.mean() * 0.01 + (1 - 0.01) * self.t\n",
    "        cos_theta[mask] = hard_example * (self.t + hard_example)\n",
    "        cos_theta.scatter_(1, label.view(-1, 1).long(), final_target_logit)\n",
    "        output = cos_theta * self.s\n",
    "        # return output, origin_cos * self.s \n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(model, img1, img2):\n",
    "    with torch.no_grad():\n",
    "        img1 = img1.cuda()\n",
    "        img2 = img2.cuda()\n",
    "        feature1 = model(img1)\n",
    "        feature2 = model(img2)\n",
    "    return feature1, feature2\n",
    "\n",
    "def cosin_metric(feature1, feature2):\n",
    "    return F.cosine_similarity(feature1, feature2)\n",
    "\n",
    "def get_acc(y_score, y_true):\n",
    "    thresholds = sorted(set(y_score), reverse=True)\n",
    "    best_acc = 0\n",
    "    best_th = 0\n",
    "    for th in thresholds:\n",
    "        y_pred = (y_score >= th).astype(int)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_th = th\n",
    "    return best_acc, best_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter\n",
    "data_df = val_df.copy()\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# dataloader\n",
    "train_dataset = FaceDataset(img_npy_list, label_npy_list, input_shape, 'train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "num_identity = len(np.unique(train_df['identity']))\n",
    "validate_every =(len(train_dataset) // batch_size) // 2 # validate every half epoch\n",
    "\n",
    "# validate dataloader\n",
    "# val_batch_size = 16\n",
    "# root = 'data/test_pair'\n",
    "# img_npy_list1 = [np.load(os.path.join(root, 'img1_0.npy'))]\n",
    "# img_npy_list2 = [np.load(os.path.join(root, 'img2_0.npy'))]\n",
    "# label_npy_list = [np.load(os.path.join(root, 'label_0.npy'))]\n",
    "\n",
    "# input_shape = (3, 250, 250)\n",
    "# pair_dataset = PairFaceDataset(img_npy_list1, img_npy_list2, label_npy_list, input_shape)\n",
    "# pair_dataloader = DataLoader(pair_dataset, batch_size=val_batch_size, shuffle=True)\n",
    "num_classes = 2\n",
    "\n",
    "# model, metric_fc, criterion, optimizer\n",
    "model = DataParallel(model_resnet)\n",
    "# metric_fc = DataParallel(ArcMarginProduct(512, num_identity, s=30, m=0.5, easy_margin=False))\n",
    "metric_fc = DataParallel(CurricularFace(512, num_identity, m=0.5, s=64.))\n",
    "model.to(device)\n",
    "metric_fc.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "weigth_decay = 5e-4\n",
    "optimizer = torch.optim.SGD([{'params': model.parameters()}, {'params': metric_fc.parameters()}], \n",
    "                                    lr=learning_rate, weight_decay=weigth_decay)\n",
    "learning_step = 1\n",
    "scheduler = StepLR(optimizer, step_size=learning_step, gamma=0.1)\n",
    "\n",
    "# writer\n",
    "exist_path = os.listdir('log')\n",
    "writer_version = int(exist_path[-1][-1]) + 1 if len(exist_path) > 0 else 0\n",
    "writer = SummaryWriter(log_dir=\"log/v\" + str(writer_version))\n",
    "step = 0\n",
    "epoch_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "count = 0\n",
    "for data, train_label in train_dataloader:\n",
    "    # forward\n",
    "    data = data.to(device)\n",
    "    train_label = train_label.to(device)\n",
    "    feature = model(data).to(device)\n",
    "    output = metric_fc(feature, train_label).to(device)\n",
    "    loss = criterion(output, train_label.long().cuda())\n",
    "    count += 1\n",
    "\n",
    "    if count == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feature = 512\n",
    "out_feature = num_identity\n",
    "m = 0.5\n",
    "s = 64.0\n",
    "cos_m = math.cos(m)\n",
    "sin_m = math.sin(m)\n",
    "threshold = math.cos(math.pi - m)\n",
    "mm = math.sin(math.pi - m) * m\n",
    "kernel = torch.Tensor(in_feature, out_feature).to(device)\n",
    "t = torch.zeros(1).to(device)\n",
    "nn.init.normal_(kernel, std=0.01)\n",
    "\n",
    "embbedings = l2_norm(feature, axis = 1)\n",
    "kernel_norm = l2_norm(kernel, axis = 0)\n",
    "cos_theta = torch.mm(embbedings, kernel_norm)\n",
    "cos_theta = cos_theta.clamp(-1, 1)  # for numerical stability\n",
    "with torch.no_grad():\n",
    "    origin_cos = cos_theta.clone()\n",
    "target_logit = cos_theta[torch.arange(0, embbedings.size(0)), train_label.long()].view(-1, 1)\n",
    "\n",
    "sin_theta = torch.sqrt(1.0 - torch.pow(target_logit, 2))\n",
    "cos_theta_m = target_logit * cos_m - sin_theta * sin_m #cos(target+margin)\n",
    "mask = cos_theta > cos_theta_m\n",
    "final_target_logit = torch.where(target_logit > threshold, cos_theta_m, target_logit - mm)\n",
    "\n",
    "hard_example = cos_theta[mask]\n",
    "with torch.no_grad():\n",
    "    t = target_logit.mean() * 0.01 + (1 - 0.01) * t\n",
    "cos_theta[mask] = hard_example * (t + hard_example)\n",
    "cos_theta.scatter_(1, train_label.view(-1, 1).long(), final_target_logit)\n",
    "output = cos_theta * s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for data, train_label in tqdm(train_dataloader, desc='Epoch {}/{}'.format(epoch+1, num_epochs)):\n",
    "        # forward\n",
    "        data = data.to(device) \n",
    "        train_label = train_label.to(device)\n",
    "        feature = model(data).to(device)\n",
    "        output = metric_fc(feature, train_label).to(device)\n",
    "        loss = criterion(output, train_label.long().cuda())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # validate\n",
    "        if step % validate_every == 0:\n",
    "            model.eval()\n",
    "            similarity_list = []\n",
    "            label_list = []\n",
    "            with torch.no_grad():\n",
    "                for data1, data2, label in pair_dataloader:\n",
    "                    data1 = data1.to(device)\n",
    "                    data2 = data2.to(device)\n",
    "                    label = label.to(device)\n",
    "                    feature1, feature2 = get_feature(model, data1, data2)\n",
    "                    similarity = cosin_metric(feature1, feature2)\n",
    "                    similarity_list.append(similarity.cpu().numpy())\n",
    "                    label_list.append(label.cpu().numpy())\n",
    "                similarity_list = np.concatenate(similarity_list)\n",
    "                label_list = np.concatenate(label_list)\n",
    "                acc, th = get_acc(similarity_list, label_list)   \n",
    "            model.train()\n",
    "\n",
    "            # visualize\n",
    "            # img_grid = make_grid(data)\n",
    "            # img = data.cpu().numpy()\n",
    "            # img = img.reshape(img.shape[0], -1)\n",
    "            # output = output.data.cpu().numpy()\n",
    "            # output = np.argmax(output, axis=1)\n",
    "            # train_label = train_label.data.cpu().numpy()\n",
    "\n",
    "            # writer.add_histogram('fc', model_resnet18.fc.weight, epoch)\n",
    "            # writer.add_image('image', img_grid, step)\n",
    "            writer.add_scalar('loss', loss.item(), step)\n",
    "            writer.add_scalar('acc', acc, step)\n",
    "            writer.add_scalar('threshold', th, step)\n",
    "            writer.add_scalar('lr', scheduler.get_last_lr()[0], step)\n",
    "            # writer.add_embedding(img, metadata=train_label, label_img=data, global_step=step)\n",
    "        step += 1\n",
    "\n",
    "    scheduler.step()\n",
    "    epoch_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_path = 'model_save/model_resnet18.pth'\n",
    "metric_fc_path = 'model_save/metric_fc.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'losses': loss,\n",
    "    'acc': acc,\n",
    "    'step': step,\n",
    "    'epoch_count': epoch_count}, model_path)\n",
    "torch.save(metric_fc.state_dict(), metric_fc_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_path = 'model_save/model_resnet18.pth'\n",
    "metric_fc_path = 'model_save/metric_fc.pth'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiogram",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
