{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter, DataParallel\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms as T\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_df(identity_root, identity_list):\n",
    "    path_list = []\n",
    "    identity_label_list = []\n",
    "    for identity in tqdm(identity_list):\n",
    "        image_list = os.listdir(os.path.join(identity_root, identity)) \n",
    "        for img in image_list:\n",
    "            path = os.path.join(identity_root, identity, img)\n",
    "            path_list.append(path)\n",
    "            identity_label_list.append(identity) \n",
    "\n",
    "    data_df = pd.DataFrame({'img_path': path_list, 'identity': identity_label_list})\n",
    "    data_df['identity_code'] = pd.Categorical(data_df['identity']).codes # convert identity to unique code(int)\n",
    "    data_df['identity_code'] = data_df['identity_code'].astype('int32')\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4599/4599 [00:00<00:00, 12329.65it/s]\n",
      "100%|██████████| 575/575 [00:00<00:00, 12688.95it/s]\n",
      "100%|██████████| 575/575 [00:00<00:00, 12632.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 10220, val: 1523, test: 1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# buid the dataframe from the the path\n",
    "identity_root = 'lfw_funneled'\n",
    "identity_list = os.listdir(identity_root)\n",
    "identity_list = [identity for identity in identity_list if os.path.isdir(os.path.join(identity_root, identity))] #only folder is identity\n",
    "\n",
    "# train test val split\n",
    "train_identity_list, test_identity_list = train_test_split(identity_list, test_size=0.2, random_state=42)\n",
    "test_identity_list, val_identity_list = train_test_split(test_identity_list, test_size=0.5, random_state=42)\n",
    "\n",
    "# build the dataframe\n",
    "train_df = get_data_df(identity_root, train_identity_list)\n",
    "test_df = get_data_df(identity_root, test_identity_list)\n",
    "val_df = get_data_df(identity_root, val_identity_list)\n",
    "print('train: {}, val: {}, test: {}'.format(len(train_df), len(val_df), len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, data_df, input_shape, phase=\"train\"):\n",
    "        self.path = data_df['img_path'].values\n",
    "        self.label = data_df['identity_code'].values\n",
    "        self.phase = phase\n",
    "        self.input_shape = input_shape\n",
    "        if self.phase == 'train':\n",
    "            self.transforms = T.Compose([\n",
    "                T.RandomCrop(self.input_shape[1:]),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.5], std=[0.5])\n",
    "            ])\n",
    "        else:   \n",
    "            self.transforms = T.Compose([\n",
    "                T.CenterCrop(self.input_shape[1:]),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.5], std=[0.5])\n",
    "            ])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = self.path[index]\n",
    "        label = self.label[index]\n",
    "        data = Image.open(path)\n",
    "        data = data.convert('L')\n",
    "        data = self.transforms(data)\n",
    "        return data.float(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "data_df = val_df.copy()\n",
    "input_shape = (1, 250, 250)\n",
    "phase = 'train'\n",
    "dataset = FaceDataset(data_df, input_shape, phase)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "num_classes = len(np.unique(data_df['identity'].values))\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 250, 250])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for data, label in dataloader:\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\earth/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n",
      "C:\\Users\\earth\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "model_resnet18 = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', weights=True)\n",
    "# change first and last layer\n",
    "model_resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model_resnet18.fc = nn.Linear(512, 512)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    r\"\"\"Implement of large margin arc distance: :\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample\n",
    "            s: norm of input feature\n",
    "            m: margin\n",
    "\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
    "        output *= self.s\n",
    "        # print(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the training step\n",
    "data_df = val_df.copy()    \n",
    "num_classes = len(np.unique(data_df['identity'].values))\n",
    "model = DataParallel(model_resnet18)\n",
    "metric_fc = DataParallel(ArcMarginProduct(512, num_classes, s=30, m=0.5, easy_margin=False))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params': metric_fc.parameters()}], lr=0.001)\n",
    "model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:18<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for data, label in tqdm(dataloader):\n",
    "    feature = model(data)\n",
    "    output = metric_fc(feature, label)\n",
    "    loss = criterion(output, label.long().cuda())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    output = output.data.cpu().numpy()\n",
    "    output = np.argmax(output, axis=1)\n",
    "    label = label.data.cpu().numpy()\n",
    "    acc = np.mean((output == label).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "data_df = data_df.copy()\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_classes = len(np.unique(data_df['identity'].values))\n",
    "\n",
    "# model, metric_fc, criterion, optimizer\n",
    "model = DataParallel(model)\n",
    "metric_fc = DataParallel(ArcMarginProduct(512, num_classes, s=30, m=0.5, easy_margin=False))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params': metric_fc.parameters()}], lr=learning_rate)\n",
    "\n",
    "# train\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for data, label in dataloader:\n",
    "        feature = model(data)\n",
    "        output = metric_fc(feature, label)\n",
    "        loss = criterion(output, label.long().cuda())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiogram",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
